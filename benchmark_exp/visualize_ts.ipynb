{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiztion of Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root directory (one level up from the 'TSB_AD' package folder)\n",
    "# to the Python path if it's not already there.\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir)) if '__file__' in locals() else os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    print(f\"Adding project root to sys.path: {project_root}\")\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Verify the path (optional)\n",
    "# print(\"\\n-- sys.path ---\")\n",
    "# print(sys.path)\n",
    "# print(\"--------------\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score\n",
    "from TSB_AD.evaluation.basic_metrics import basic_metricor\n",
    "\n",
    "def plot_func_ts(data, label, file_name):\n",
    "\n",
    "    grader = basic_metricor()\n",
    "    range_anomaly = grader.range_convers_new(label)\n",
    "\n",
    "    # Create the main trace\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(len(data))),\n",
    "        y=data,\n",
    "        mode='lines',\n",
    "        line=dict(color='#0248b5', width=2),      # [#0b5920, 0248b5]\n",
    "        name='Time Series'\n",
    "    ))\n",
    "\n",
    "    # Highlight anomalies\n",
    "    for r in range_anomaly:\n",
    "        if r[0] == r[1]:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[r[0]],\n",
    "                y=[data[r[0]]],\n",
    "                mode='markers',\n",
    "                marker=dict(color='red', size=5),\n",
    "                name='Anomaly Point'\n",
    "            ))\n",
    "        else:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=list(range(r[0], r[1]+1)),\n",
    "                y=data[r[0]:r[1]+1],\n",
    "                mode='lines',\n",
    "                line=dict(color='red', width=2),\n",
    "                name=f'Anomaly Range {r[0]}-{r[1]}'\n",
    "            ))\n",
    "    fig.update_layout(title=file_name, height=300, plot_bgcolor='white', paper_bgcolor='white',     \n",
    "        xaxis=dict(\n",
    "        tickfont=dict(size=18),\n",
    "        showline=True,\n",
    "        linecolor='black',\n",
    "        linewidth=2\n",
    "        ))\n",
    "    return fig\n",
    "\n",
    "def plot_func_score(label, anomaly_score, file_name):\n",
    "    auc_roc = roc_auc_score(label, anomaly_score)\n",
    "    auc_pr = average_precision_score(label, anomaly_score)\n",
    "\n",
    "    thresholds = np.linspace(anomaly_score.min(), anomaly_score.max(), 100)\n",
    "    f1_scores = []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        predictions = (anomaly_score > threshold).astype(int)\n",
    "        f1 = f1_score(label, predictions)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    best_f1_score = max(f1_scores)\n",
    "\n",
    "    predictions = (anomaly_score > best_threshold).astype(int)\n",
    "\n",
    "    false_negatives = np.where((label == 1) & (predictions == 0))[0]\n",
    "    false_positives = np.where((label == 0) & (predictions == 1))[0]\n",
    "    true_positives = np.where((label == 1) & (predictions == 1))[0]\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(len(anomaly_score))),\n",
    "        y=anomaly_score,\n",
    "        mode='lines',\n",
    "        line=dict(color='#26a9b5', width=1.5),\n",
    "        name='Anomaly Score'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[0, len(anomaly_score) - 1],\n",
    "        y=[best_threshold, best_threshold],\n",
    "        mode='lines',\n",
    "        line=dict(color='red', width=1, dash='dash'),\n",
    "        name='Threshold'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=false_negatives,\n",
    "        y=anomaly_score[false_negatives],\n",
    "        mode='markers',\n",
    "        marker=dict(color='orange', size=5, symbol='x'),\n",
    "        name='False Negatives'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=false_positives,\n",
    "        y=anomaly_score[false_positives],\n",
    "        mode='markers',\n",
    "        marker=dict(color='purple', size=5, symbol='circle'),\n",
    "        name='False Positives'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=true_positives,\n",
    "        y=anomaly_score[true_positives],\n",
    "        mode='markers',\n",
    "        marker=dict(color='green', size=5, symbol='star'),\n",
    "        name='True Positives'\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"{file_name}<br>AUC-ROC: {auc_roc:.2f}, AUC-PR: {auc_pr:.2f}, Best F1: {best_f1_score:.2f}\",\n",
    "        height=300,\n",
    "        xaxis=dict(\n",
    "            tickfont=dict(size=18),\n",
    "            title='Time',\n",
    "            showline=True,\n",
    "            linecolor='black',\n",
    "            linewidth=2\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Anomaly Score',\n",
    "            showline=True,\n",
    "            linecolor='black',\n",
    "            linewidth=2\n",
    "        ),\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  (16220,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from TSB_AD.evaluation.metrics import get_metrics\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\" # Set default renderer for VS Code\n",
    "file_name = '001_Genesis_id_1_Sensor_tr_4055_1st_15538'\n",
    "df = pd.read_csv(f'../Datasets/TSB-AD-M/{file_name}.csv').dropna()\n",
    "data = df.iloc[:, 0].values.astype(float)\n",
    "label = df['Label'].astype(int).to_numpy()\n",
    "print('data: ', data.shape)\n",
    "\n",
    "# anomaly_score = np.load('')\n",
    "# metrics = get_metrics(anomaly_score, label, slidingWindow=100)\n",
    "\n",
    "fig_ts = plot_func_ts(data, label, file_name)\n",
    "fig_ts.show()\n",
    "# fig_score = plot_func_score(label, anomaly_score, 'Anomaly Score')\n",
    "# fig_score.show()\n",
    "# print('metrics: ', metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
